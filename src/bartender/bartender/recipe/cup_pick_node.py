#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import rclpy
from rclpy.node import Node
import DR_init
from std_msgs.msg import String

import cv2
import numpy as np
from ultralytics import YOLO
from cv_bridge import CvBridge
from sensor_msgs.msg import Image, CameraInfo
from scipy.spatial.transform import Rotation
from ament_index_python.packages import get_package_share_directory
from rclpy.qos import qos_profile_sensor_data


# ========================================
# ë¡œë´‡ ì„¤ì •
# ========================================
ROBOT_ID = "dsr01"
ROBOT_MODEL = "m0609"
ROBOT_TOOL = "Tool Weight"
ROBOT_TCP = "GripperDA_v2"

VELJ = 60
ACCJ = 60
J_READY = [0, 0, 90, 0, 90, 0]


class BartenderBot(Node):
    def __init__(self):
        super().__init__("bartender_bot", namespace=ROBOT_ID)

        self.status_pub = self.create_publisher(String, "status", 10)
        self.bridge = CvBridge()

        self.color_frame = None
        self.depth_frame = None
        self.intrinsics = None

        # === ê²½ë¡œ ì„¤ì • ===
        pkg_share = get_package_share_directory("bartender")
        recipe_dir = os.path.join(pkg_share, "recipe")
        transform_path = os.path.join(recipe_dir, "T_gripper2camera.npy")

        # YOLO ëª¨ë¸ (ì ˆëŒ€ê²½ë¡œ, ë””ë²„ê¹…ìš©)
        model_path = "/home/dabom/dynamic_busan/src/bartender/bartender/recipe/yolov8n.pt"
        self.yolo = YOLO(model_path)

        if os.path.exists(transform_path):
            self.gripper2cam = np.load(transform_path)
        else:
            self.get_logger().warn("âš ï¸ hand-eye íŒŒì¼ ì—†ìŒ â†’ identity ì‚¬ìš©")
            self.gripper2cam = np.eye(4)

        # ì¹´ë©”ë¼ êµ¬ë…
        self.create_subscription(
            Image, "/camera/camera/color/image_raw",
            self.color_cb, qos_profile_sensor_data
        )
        self.create_subscription(
            Image, "/camera/camera/aligned_depth_to_color/image_raw",
            self.depth_cb, qos_profile_sensor_data
        )
        self.create_subscription(
            CameraInfo, "/camera/camera/color/camera_info",
            self.info_cb, qos_profile_sensor_data
        )

        self.get_logger().info("BartenderBot ì´ˆê¸°í™” ì™„ë£Œ")

    # ===============================
    # ì½œë°±
    # ===============================
    def color_cb(self, msg):
        self.color_frame = self.bridge.imgmsg_to_cv2(msg, "bgr8")

    def depth_cb(self, msg):
        self.depth_frame = self.bridge.imgmsg_to_cv2(msg, "passthrough")

    def info_cb(self, msg):
        if self.intrinsics is None:
            self.intrinsics = {
                "fx": msg.k[0],
                "fy": msg.k[4],
                "ppx": msg.k[2],
                "ppy": msg.k[5],
            }

    # ===============================
    # ì¹´ë©”ë¼ ëŒ€ê¸°
    # ===============================
    def wait_camera(self):
        self.get_logger().info("ì¹´ë©”ë¼ ë°ì´í„° ëŒ€ê¸° ì¤‘...")
        while rclpy.ok():
            rclpy.spin_once(self, timeout_sec=0.1)
            if self.color_frame is not None and self.depth_frame is not None and self.intrinsics:
                return True
        return False

    # ===============================
    # ì»µ íƒì§€ (ë””ë²„ê¹… í•µì‹¬)
    # ===============================
    def find_object(self):
        if not self.wait_camera():
            return None

        frame = self.color_frame.copy()

        results = self.yolo.predict(
            frame,
            conf=0.05,      # ğŸ”¥ ê·¹ë‹¨ì ìœ¼ë¡œ ë‚®ì¶¤ (ì§„ë‹¨ìš©)
            verbose=False
        )

        debug_img = results[0].plot()
        cv2.imwrite("debug_detection.jpg", debug_img)
        self.get_logger().info("debug_detection.jpg ì €ì¥ ì™„ë£Œ")

        if len(results[0].boxes) == 0:
            self.get_logger().warn("âŒ YOLO ê²€ì¶œ ê²°ê³¼ 0ê°œ")
            return None

        # ëª¨ë“  ê²€ì¶œ ë¡œê·¸ ì¶œë ¥
        for box in results[0].boxes:
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            self.get_logger().info(f"Detected class={cls}, conf={conf:.2f}")

        # 1. íƒ€ê²Ÿ í´ë˜ìŠ¤ë§Œ í•„í„°ë§ (41:cup, 39:bottle, 45:bowl)
        target_classes = [41, 71, 39, 45]
        candidates = [b for b in results[0].boxes if int(b.cls[0]) in target_classes]

        if not candidates:
            self.get_logger().warn("âŒ íƒ€ê²Ÿ ë¬¼ì²´(ì»µ, ë³‘, ê·¸ë¦‡)ê°€ ê²€ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # ê°€ì¥ í° ë°•ìŠ¤ë¥¼ ì»µ í›„ë³´ë¡œ ì„ íƒ
        best = max(
            candidates,
            key=lambda b: (b.xyxy[0][2] - b.xyxy[0][0]) *
                          (b.xyxy[0][3] - b.xyxy[0][1])
        )

        x1, y1, x2, y2 = best.xyxy[0].cpu().numpy()
        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)

        # 2. ê¹Šì´ê°’ ë³´ì • (ì¤‘ì‹¬ì  ì£¼ë³€ 10x10 ì˜ì—­ì˜ ì¤‘ì•™ê°’ ì‚¬ìš©)
        # depth=0ì¸ í”½ì…€(ê²°ì¸¡ì¹˜)ì„ ì œì™¸í•˜ê³  ê³„ì‚°í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
        roi = self.depth_frame[max(0, cy-5):min(cy+5, self.depth_frame.shape[0]), max(0, cx-5):min(cx+5, self.depth_frame.shape[1])]
        valid_depths = roi[roi > 0]

        if len(valid_depths) == 0:
            self.get_logger().warn(f"âŒ ì¤‘ì‹¬ì ({cx},{cy}) ì£¼ë³€ ê¹Šì´ ì •ë³´ ì—†ìŒ (depth=0)")
            return None

        depth = np.median(valid_depths)
        cam_x = (cx - self.intrinsics["ppx"]) * depth / self.intrinsics["fx"]
        cam_y = (cy - self.intrinsics["ppy"]) * depth / self.intrinsics["fy"]
        cam_z = float(depth)

        self.get_logger().info(
            f"í”½ì…€=({cx},{cy}), depth={depth}mm, cam=({cam_x:.1f},{cam_y:.1f},{cam_z:.1f})"
        )

        return cam_x, cam_y, cam_z

    # ===============================
    # ë¡œë´‡ ìœ í‹¸ë¦¬í‹°
    # ===============================
    def grip(self):
        from DSR_ROBOT2 import set_digital_output
        self.get_logger().info("GRIP ON")
        set_digital_output(1, 1)
        set_digital_output(2, 0)
        time.sleep(0.3)

    def release(self):
        from DSR_ROBOT2 import set_digital_output
        self.get_logger().info("GRIP OFF")
        set_digital_output(1, 0)
        set_digital_output(2, 1)
        time.sleep(0.3)

    def transform_to_base(self, cam_pos):
        from DSR_ROBOT2 import get_current_posx
        
        cx, cy, cz = cam_pos
        # 1. ì¹´ë©”ë¼ ì¢Œí‘œê³„ ì  (Homogeneous)
        p_cam = np.array([cx, cy, cz, 1.0])
        
        # 2. Gripper ì¢Œí‘œê³„ë¡œ ë³€í™˜ (Hand-Eye Calibration)
        p_grp = self.gripper2cam @ p_cam
        
        # 3. Base ì¢Œí‘œê³„ë¡œ ë³€í™˜ (Robot Kinematics)
        # í˜„ì¬ ë¡œë´‡ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸° (x, y, z, a, b, c) - Euler ZYZ
        curr_pos = get_current_posx()[0]
        x, y, z, a, b, c = curr_pos
        
        # íšŒì „ í–‰ë ¬ ìƒì„± (Doosanì€ ZYZ Euler angle ì‚¬ìš©)
        R = Rotation.from_euler('ZYZ', [a, b, c], degrees=True).as_matrix()
        T_base_grp = np.eye(4)
        T_base_grp[:3, :3] = R
        T_base_grp[:3, 3] = [x, y, z]
        
        p_base = T_base_grp @ p_grp
        return p_base[:3]

    # ===============================
    # ì‹¤í–‰
    # ===============================

    def run(self):
        self.get_logger().info("ì»µ í”½ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")

        from DSR_ROBOT2 import movej, movel, posx, wait, DR_MV_MOD_REL

        # 1. ìŠ¤ìº” ìœ„ì¹˜
        movej(J_READY, vel=VELJ, acc=ACCJ)
        wait(1.0)

        # 2. ì»µ ì¸ì‹ (ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸)
        pos = self.find_object()
        if pos is None:
            self.get_logger().error("âŒ ì»µ ì¸ì‹ ì‹¤íŒ¨ â†’ ì‘ì—… ì¢…ë£Œ")
            return

        self.get_logger().info("âœ… ì»µ ì¸ì‹ ì„±ê³µ")

        # 3. ì¢Œí‘œ ë³€í™˜ (Camera -> Base)
        bx, by, bz = self.transform_to_base(pos)
        self.get_logger().info(f"ğŸ¯ ë³€í™˜ëœ íƒ€ê²Ÿ ì¢Œí‘œ: {bx:.2f}, {by:.2f}, {bz:.2f}")
        rx, ry, rz = 19.83, 180.0, 19.28

        # 4. ì ‘ê·¼
        self.release()
        movel(posx([bx, by, bz + 100, rx, ry, rz]), vel=[100, 100], acc=[100, 100])
        wait(0.3)

        # 5. í”½
        movel(posx([bx, by, bz - 20, rx, ry, rz]), vel=[50, 50], acc=[50, 50])
        wait(0.2)
        self.grip()
        wait(0.5)

        # 6. ë¦¬í”„íŠ¸
        movel(posx([0, 0, 150, 0, 0, 0]),
            vel=[100, 100], acc=[100, 100], mod=DR_MV_MOD_REL)
        wait(0.5)

        # 7. í™ˆ ìœ„ì¹˜ë¡œ ì´ë™ (ì»µ ë“¤ê³  ì´ë™)
        self.get_logger().info("í™ˆ ìœ„ì¹˜ë¡œ ì´ë™")
        movej(J_READY, vel=VELJ, acc=ACCJ)
        wait(1.0)

        # 8. ë‚´ë ¤ë†“ê¸° (í™ˆ ìœ„ì¹˜ ê¸°ì¤€)
        self.get_logger().info("ì»µ ë‚´ë ¤ë†“ê¸°")
        movel(posx([0, 0, -80, 0, 0, 0]),
            vel=[50, 50], acc=[50, 50], mod=DR_MV_MOD_REL)
        wait(0.3)

        self.release()
        wait(0.5)

        # 9. ë³µê·€
        movel(posx([0, 0, 80, 0, 0, 0]),
            vel=[100, 100], acc=[100, 100], mod=DR_MV_MOD_REL)
        wait(0.5)

        self.get_logger().info("âœ… ì»µ í”½ & í”Œë ˆì´ìŠ¤ ì™„ë£Œ")


def main():
    rclpy.init()
    DR_init.__dsr__id = ROBOT_ID
    DR_init.__dsr__model = ROBOT_MODEL

    node = BartenderBot()
    DR_init.__dsr__node = node

    try:
        node.run()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()